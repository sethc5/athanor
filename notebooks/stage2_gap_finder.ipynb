{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318ffcec",
   "metadata": {},
   "source": [
    "# Athanor — Stage 2: Gap Finder\n",
    "\n",
    "**Input:** Stage 1 outputs — `concept_graph.json` + `candidate_gaps.json`  \n",
    "**Process:** Claude analyses each semantically-close / graph-distant concept pair → structured research question  \n",
    "**Output:** `outputs/gaps/gap_report.json` — ranked research questions ready for Stage 3\n",
    "\n",
    "**Pipeline:** `Load graph → Enrich candidates → Claude analysis → Score & rank → Visualize → Save`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6aaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path(\"..\") / \".env\")\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "console = Console()\n",
    "print(\"✓ Imports OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11327a2",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Edit this block to change domain or tune the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Must match Stage 1\n",
    "    \"domain\": \"information theory\",\n",
    "    \"claude_model\": \"claude-opus-4-5\",\n",
    "\n",
    "    # How many candidate gaps to send to Claude (controls API cost; ~$0.05–0.15 each)\n",
    "    \"max_gaps_to_analyse\": 15,\n",
    "\n",
    "    # Stage 1 outputs (read)\n",
    "    \"graph_path\": Path(\"..\") / \"outputs\" / \"graphs\" / \"concept_graph.json\",\n",
    "    \"gaps_path\":  Path(\"..\") / \"outputs\" / \"graphs\" / \"candidate_gaps.json\",\n",
    "\n",
    "    # Stage 2 outputs (write)\n",
    "    \"output_dir\": Path(\"..\") / \"outputs\" / \"gaps\",\n",
    "}\n",
    "\n",
    "CONFIG[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "    console.print(\"[bold red]ANTHROPIC_API_KEY not set![/]\")\n",
    "else:\n",
    "    console.print(f\"[bold green]✓ Config ready[/] — model: {CONFIG['claude_model']}, max gaps: {CONFIG['max_gaps_to_analyse']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec1587",
   "metadata": {},
   "source": [
    "## 2. Load Stage 1 Outputs\n",
    "\n",
    "Read the concept graph and candidate gaps produced by Stage 1.  \n",
    "**Stage 1 must be run first** — if files are missing, run `stage1_literature_mapper.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17643e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from athanor.graph.models import ConceptGraph\n",
    "from athanor.gaps.models import CandidateGap\n",
    "\n",
    "# ── Load concept graph ────────────────────────────────────────────────────────\n",
    "if not CONFIG[\"graph_path\"].exists():\n",
    "    console.print(f\"[bold red]Missing:[/] {CONFIG['graph_path']}\\nRun Stage 1 first.\")\n",
    "    raise FileNotFoundError(CONFIG[\"graph_path\"])\n",
    "\n",
    "concept_graph = ConceptGraph.model_validate_json(\n",
    "    CONFIG[\"graph_path\"].read_text()\n",
    ")\n",
    "\n",
    "# Build label → concept lookup for context enrichment\n",
    "concept_map = {c.label: c for c in concept_graph.concepts}\n",
    "\n",
    "console.print(f\"[bold green]✓ Concept graph loaded[/] — {len(concept_graph.concepts)} concepts, {len(concept_graph.edges)} edges\")\n",
    "\n",
    "# ── Load candidate gaps ───────────────────────────────────────────────────────\n",
    "if not CONFIG[\"gaps_path\"].exists():\n",
    "    console.print(f\"[bold red]Missing:[/] {CONFIG['gaps_path']}\\nRun Stage 1 first.\")\n",
    "    raise FileNotFoundError(CONFIG[\"gaps_path\"])\n",
    "\n",
    "raw_gaps = json.loads(CONFIG[\"gaps_path\"].read_text())\n",
    "candidate_gaps = [CandidateGap(**g) for g in raw_gaps]\n",
    "\n",
    "console.print(f\"[bold green]✓ Candidate gaps loaded[/] — {len(candidate_gaps)} pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e870e",
   "metadata": {},
   "source": [
    "## 3. Enrich Candidates with Concept Context\n",
    "\n",
    "Inject descriptions and provenance from the concept graph into each gap.  \n",
    "This is the context Claude uses to reason about *why* the gap exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f23824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = concept_graph.to_networkx()\n",
    "enriched: list[CandidateGap] = []\n",
    "\n",
    "for gap in candidate_gaps:\n",
    "    ca = concept_map.get(gap.concept_a)\n",
    "    cb = concept_map.get(gap.concept_b)\n",
    "\n",
    "    # Shared papers: concepts that appear in papers referencing both endpoints\n",
    "    papers_a = set(ca.source_papers) if ca else set()\n",
    "    papers_b = set(cb.source_papers) if cb else set()\n",
    "    shared = sorted(papers_a & papers_b)\n",
    "\n",
    "    enriched.append(\n",
    "        CandidateGap(\n",
    "            concept_a=gap.concept_a,\n",
    "            concept_b=gap.concept_b,\n",
    "            similarity=gap.similarity,\n",
    "            graph_distance=gap.graph_distance,\n",
    "            description_a=ca.description if ca else \"\",\n",
    "            description_b=cb.description if cb else \"\",\n",
    "            shared_papers=shared,\n",
    "            papers_a=sorted(papers_a - papers_b)[:4],\n",
    "            papers_b=sorted(papers_b - papers_a)[:4],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Sort by similarity desc (most semantically close = highest priority gap)\n",
    "enriched.sort(key=lambda g: g.similarity, reverse=True)\n",
    "\n",
    "table = Table(title=\"Top 10 Enriched Candidate Gaps\", show_lines=True)\n",
    "table.add_column(\"Concept A\", style=\"cyan\")\n",
    "table.add_column(\"Concept B\", style=\"cyan\")\n",
    "table.add_column(\"Sim\", style=\"green\")\n",
    "table.add_column(\"Dist\", style=\"red\")\n",
    "table.add_column(\"Shared Papers\", style=\"yellow\")\n",
    "\n",
    "for g in enriched[:10]:\n",
    "    table.add_row(\n",
    "        g.concept_a,\n",
    "        g.concept_b,\n",
    "        f\"{g.similarity:.3f}\",\n",
    "        str(g.graph_distance) if g.graph_distance < 999 else \"∞\",\n",
    "        str(len(g.shared_papers)),\n",
    "    )\n",
    "\n",
    "console.print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2a9db",
   "metadata": {},
   "source": [
    "## 4. Gap Analysis via Claude\n",
    "\n",
    "For each gap, Claude produces:\n",
    "- A precise, testable **research question**\n",
    "- **Why** the community has missed this connection\n",
    "- The **opportunity** at this intersection\n",
    "- A concrete **methodology** sketch\n",
    "- Scores: novelty · tractability · impact (1–5 each)\n",
    "\n",
    "Results are cached to disk — re-running this cell is free after the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from athanor.gaps import GapFinder, GapReport, GapAnalysis\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "cache_path = CONFIG[\"output_dir\"] / \"gap_report_cache.json\"\n",
    "\n",
    "if cache_path.exists():\n",
    "    console.print(\"[yellow]Loading cached gap report…[/]\")\n",
    "    gap_report = GapReport.model_validate_json(cache_path.read_text())\n",
    "else:\n",
    "    finder = GapFinder(\n",
    "        domain=CONFIG[\"domain\"],\n",
    "        model=CONFIG[\"claude_model\"],\n",
    "        api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "        max_gaps=CONFIG[\"max_gaps_to_analyse\"],\n",
    "    )\n",
    "\n",
    "    # Wrap with tqdm for progress visibility\n",
    "    gaps_to_analyse = enriched[: CONFIG[\"max_gaps_to_analyse\"]]\n",
    "    gap_report = GapReport(\n",
    "        domain=CONFIG[\"domain\"],\n",
    "        query=concept_graph.query,\n",
    "        n_candidates=len(enriched),\n",
    "        n_analyzed=len(gaps_to_analyse),\n",
    "    )\n",
    "\n",
    "    for i, gap in enumerate(tqdm(gaps_to_analyse, desc=\"Analysing gaps\")):\n",
    "        console.print(f\"  [{i+1}/{len(gaps_to_analyse)}] [cyan]{gap.concept_a}[/] ↔ [cyan]{gap.concept_b}[/]\")\n",
    "        analysis = finder._analyse_one(gap)\n",
    "        if analysis:\n",
    "            gap_report.analyses.append(analysis)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Cache\n",
    "    cache_path.write_text(gap_report.model_dump_json(indent=2))\n",
    "    console.print(f\"\\n[green]✓ Cached to {cache_path}[/]\")\n",
    "\n",
    "console.print(\n",
    "    f\"\\n[bold green]✓ Gap report ready[/] — \"\n",
    "    f\"{len(gap_report.analyses)} analyses from {gap_report.n_candidates} candidates\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8fb2a4",
   "metadata": {},
   "source": [
    "## 5. Score & Rank\n",
    "\n",
    "Composite score = `impact × 0.4 + novelty × 0.35 + tractability × 0.25`  \n",
    "Weighted toward impact because high-novelty/low-impact gaps aren't the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = gap_report.ranked  # sorted by composite_score desc\n",
    "\n",
    "score_table = Table(\n",
    "    title=f\"All Gap Analyses — {CONFIG['domain']} (ranked by composite score)\",\n",
    "    show_lines=True,\n",
    ")\n",
    "score_table.add_column(\"#\", style=\"dim\", width=3)\n",
    "score_table.add_column(\"Concept A\", style=\"cyan\")\n",
    "score_table.add_column(\"Concept B\", style=\"cyan\")\n",
    "score_table.add_column(\"Score\", style=\"bold green\")\n",
    "score_table.add_column(\"Nov\", style=\"magenta\")\n",
    "score_table.add_column(\"Trc\", style=\"blue\")\n",
    "score_table.add_column(\"Imp\", style=\"red\")\n",
    "score_table.add_column(\"Comp?\", style=\"yellow\")\n",
    "score_table.add_column(\"Research Question\", style=\"white\")\n",
    "\n",
    "for i, a in enumerate(ranked, 1):\n",
    "    score_table.add_row(\n",
    "        str(i),\n",
    "        a.concept_a,\n",
    "        a.concept_b,\n",
    "        f\"{a.composite_score:.2f}\",\n",
    "        str(a.novelty),\n",
    "        str(a.tractability),\n",
    "        str(a.impact),\n",
    "        \"✓\" if a.computational else \"✗\",\n",
    "        a.research_question[:80] + (\"…\" if len(a.research_question) > 80 else \"\"),\n",
    "    )\n",
    "\n",
    "console.print(score_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa4142",
   "metadata": {},
   "source": [
    "## 6. Top 5 Gaps — Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76564f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a in enumerate(gap_report.top, 1):\n",
    "    label = f\"#{i} | Score {a.composite_score:.2f} | Nov:{a.novelty} Trc:{a.tractability} Imp:{a.impact} {'[COMP]' if a.computational else '[WET]'}\"\n",
    "    body = Text()\n",
    "    body.append(f\"Gap:  {a.concept_a}  ↔  {a.concept_b}\\n\", style=\"bold cyan\")\n",
    "    body.append(f\"\\nRQ:   {a.research_question}\\n\", style=\"bold white\")\n",
    "    body.append(f\"\\nWhy unexplored:\\n{a.why_unexplored}\\n\", style=\"dim\")\n",
    "    body.append(f\"\\nOpportunity:\\n{a.intersection_opportunity}\\n\", style=\"green\")\n",
    "    body.append(f\"\\nMethodology:\\n{a.methodology}\\n\", style=\"yellow\")\n",
    "    body.append(f\"\\nKeywords: {', '.join(a.keywords)}\", style=\"magenta\")\n",
    "    console.print(Panel(body, title=label, border_style=\"green\" if i == 1 else \"blue\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a00028",
   "metadata": {},
   "source": [
    "## 7. Visualize the Gap Landscape\n",
    "\n",
    "Scatter plot of all analysed gaps.  \n",
    "- **X axis:** tractability (how easy is it to investigate?)  \n",
    "- **Y axis:** novelty (how unstudied is this?)  \n",
    "- **Size:** impact score  \n",
    "- **Color:** composite score  \n",
    "- **Ideal gaps:** top-right, large — novel, tractable, high-impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d765d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "analyses = gap_report.ranked\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[a.tractability + (i * 0.05) for i, a in enumerate(analyses)],  # jitter\n",
    "    y=[a.novelty     + (i * 0.03) for i, a in enumerate(analyses)],\n",
    "    mode=\"markers+text\",\n",
    "    text=[f\"{a.concept_a[:12]}↔{a.concept_b[:12]}\" for a in analyses],\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=8),\n",
    "    hovertext=[\n",
    "        f\"<b>{a.concept_a} ↔ {a.concept_b}</b><br>\"\n",
    "        f\"Score: {a.composite_score:.2f}<br>\"\n",
    "        f\"Nov:{a.novelty} Trc:{a.tractability} Imp:{a.impact}<br>\"\n",
    "        f\"<i>{a.research_question[:100]}…</i>\"\n",
    "        for a in analyses\n",
    "    ],\n",
    "    hoverinfo=\"text\",\n",
    "    marker=dict(\n",
    "        size=[6 + a.impact * 4 for a in analyses],\n",
    "        color=[a.composite_score for a in analyses],\n",
    "        colorscale=\"Viridis\",\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"Composite Score\"),\n",
    "        line=dict(width=1, color=\"white\"),\n",
    "        symbol=[\"circle\" if a.computational else \"diamond\" for a in analyses],\n",
    "    ),\n",
    "))\n",
    "\n",
    "# Quadrant annotation\n",
    "for x, y, label in [\n",
    "    (4.5, 4.5, \"★ PRIORITY\"),\n",
    "    (1.5, 4.5, \"Novel but hard\"),\n",
    "    (4.5, 1.5, \"Easy but known\"),\n",
    "    (1.5, 1.5, \"Low priority\"),\n",
    "]:\n",
    "    fig.add_annotation(x=x, y=y, text=label, showarrow=False,\n",
    "                       font=dict(color=\"rgba(200,200,200,0.4)\", size=11))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Gap Landscape — {CONFIG['domain']} (● = computational, ◆ = requires wet lab)\",\n",
    "    xaxis=dict(title=\"Tractability →\", range=[0.5, 5.8], dtick=1),\n",
    "    yaxis=dict(title=\"Novelty →\", range=[0.5, 5.8], dtick=1),\n",
    "    height=600,\n",
    "    plot_bgcolor=\"#111\",\n",
    "    paper_bgcolor=\"#111\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "# Add quadrant lines\n",
    "fig.add_hline(y=3, line_dash=\"dash\", line_color=\"rgba(255,255,255,0.15)\")\n",
    "fig.add_vline(x=3, line_dash=\"dash\", line_color=\"rgba(255,255,255,0.15)\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save\n",
    "landscape_path = CONFIG[\"output_dir\"] / \"gap_landscape.html\"\n",
    "fig.write_html(str(landscape_path))\n",
    "console.print(f\"[green]✓ Gap landscape saved → {landscape_path}[/]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdd68c",
   "metadata": {},
   "source": [
    "## 8. Save GapReport — Stage 3 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ee085",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = CONFIG[\"output_dir\"] / \"gap_report.json\"\n",
    "report_path.write_text(gap_report.model_dump_json(indent=2))\n",
    "\n",
    "console.print(f\"[bold green]✓ GapReport saved → {report_path}[/]\")\n",
    "console.print(f\"\\n[bold]Summary:[/]\")\n",
    "console.print(f\"  Candidates evaluated: {gap_report.n_candidates}\")\n",
    "console.print(f\"  Analyses produced:    {len(gap_report.analyses)}\")\n",
    "console.print(f\"  Top score:            {gap_report.ranked[0].composite_score:.2f}\" if gap_report.analyses else \"  (no analyses)\")\n",
    "\n",
    "if gap_report.analyses:\n",
    "    best = gap_report.ranked[0]\n",
    "    console.print(f\"\\n[bold green]Top gap:[/] {best.concept_a} ↔ {best.concept_b}\")\n",
    "    console.print(f\"[white]{best.research_question}[/]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972770c",
   "metadata": {},
   "source": [
    "## Stage 2 Complete ✓\n",
    "\n",
    "**Outputs produced:**\n",
    "| File | Contents |\n",
    "|------|----------|\n",
    "| `outputs/gaps/gap_report_cache.json` | Raw Claude responses (cached) |\n",
    "| `outputs/gaps/gap_report.json` | Ranked GapReport — **Stage 3 input** |\n",
    "| `outputs/gaps/gap_landscape.html` | Interactive novelty × tractability scatter |\n",
    "\n",
    "---\n",
    "\n",
    "**To change domain:** update `CONFIG[\"domain\"]` and `CONFIG[\"graph_path\"]`/`CONFIG[\"gaps_path\"]` to point at a different Stage 1 run.  \n",
    "Delete `gap_report_cache.json` to force re-analysis.\n",
    "\n",
    "---\n",
    "\n",
    "**Stage 3** will read the top gaps from `gap_report.json` and for each one:  \n",
    "- Propose a concrete experiment design  \n",
    "- Generate synthetic data / computational test where possible  \n",
    "- Flag what requires wet lab or real-world validation and why  \n",
    "- Close the loop: hypothesis → evidence → refined hypothesis\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
