{
  "domain": "Information Theory ↔ Quantum Computing",
  "query": "Cross-domain bridge between:\nDOMAIN A (information_theory): Mathematical theory of information transmission, compression, storage, and inference. Spans classical Shannon theory, algorithmic information theory, quantum information, and modern connections to machine learning, statistical physics, neuroscience, and biology.\n\nDOMAIN B (quantum_computing): Quantum computation spanning near-term NISQ devices, quantum error correction, fault-tolerant architectures, and quantum algorithms. Active intersection with information theory, condensed matter, and cryptography. Real gaps exist between theoretical thresholds and engineering realities.\n\nFocus on mechanisms that could translate concepts or methods between these fields.",
  "n_candidates": 10,
  "n_analyzed": 10,
  "analyses": [
    {
      "concept_a": "Stochastic representation",
      "concept_b": "stochastic noise",
      "research_question": "Can stochastic representations of quantum channels and observables be designed such that their inherent sampling noise follows controlled, characterizable probability distributions that enable efficient classical simulation or error mitigation?",
      "why_unexplored": "Stochastic representations in quantum computing (e.g., Feynman-Kitaev, quasi-probability decompositions) are typically studied for expressiveness and classical simulability, while stochastic noise models focus on characterizing decoherence and error types. The literature treats these as separate concerns: representations are chosen for computational convenience, and noise is treated as an external perturbation. The productive direction—designing representations whose intrinsic noise structure matches or exploits known noise models—remains largely absent from both communities.",
      "intersection_opportunity": "A unified framework could exploit the duality between stochastic representations and stochastic noise to: (1) design quantum algorithms and error mitigation schemes that deliberately harness structured noise as a computational resource rather than fighting it, and (2) develop classical shadow/sampling-based methods whose convergence guarantees account for the natural noise profile of the quantum device, rather than assuming arbitrary error. This could yield more efficient, device-tailored simulation and error suppression strategies.",
      "methodology": "First, formally characterize how different stochastic decompositions (Pauli-basis expansions, Feynman-Kitaev, quasi-probability frames) naturally induce or amplify specific noise signatures during their classical sampling. Second, construct explicit mappings between families of stochastic representations and families of realistic quantum noise channels (depolarizing, dephasing, amplitude damping). Third, design a proof-of-concept algorithm that selects or parameterizes its stochastic representation to minimize classical sampling variance *given* the device's known noise profile. Finally, validate on simulated and real quantum hardware (IBMQ, IonQ) by comparing convergence and fidelity against baseline (representation-agnostic) noise models.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "stochastic representation quantum computing",
        "quasi-probability decomposition noise",
        "classical shadow sampling noise robustness",
        "device-tailored error mitigation",
        "stochastic noise channels simulation"
      ],
      "similarity": 0.5856603384017944,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "Stochastic representation",
      "concept_b": "non-stochastic noise",
      "research_question": "Can stochastic representations faithfully encode the information-theoretic properties of non-stochastic noise channels in quantum systems, and if not, what structural information is irretrievably lost in such decompositions?",
      "why_unexplored": "The quantum information community has historically treated stochastic (Kraus/Choi) representations as universal sufficient descriptions of quantum channels, while non-stochastic noise (coherent errors, time-correlated dephasing, Hamiltonian drift) is studied separately in control theory and experimental implementations. The field lacks a principled framework that asks: *when* does a stochastic model fail to capture the essential structure of realistic noise, and *why*? This gap persists because noise characterization and channel formalism evolved in parallel silos.",
      "intersection_opportunity": "Developing a formal hierarchy of noise representations—from fully stochastic (product channels) through partially coherent (Lindblad with structure) to deterministic-correlated—would enable: (1) diagnostics for whether stochastic models suffice for a given quantum algorithm's error correction needs; (2) new bounds on the minimum randomness required to *approximate* realistic noise; (3) algorithmic methods to extract classical simulability from non-stochastic structure. This would unify noise modeling with information-theoretic capacity results.",
      "methodology": "First, reformulate non-stochastic noise (e.g., time-correlated dephasing, Rabi oscillations, parametric errors) as explicit Hamiltonian channels and characterize their Choi matrices. Second, compute the Kraus rank of their closest stochastic approximation under various distances (diamond norm, JT divergence). Third, prove lower bounds on the fidelity loss when projecting non-stochastic channels onto stochastic subspaces. Fourth, test whether quantum error correction codes optimized for stochastic noise fail predictably on real hardware with non-stochastic error profiles (using existing experimental datasets from IBM, IonQ). Finally, develop a structural invariant (e.g., a non-Markovian signature or coherence measure) that predicts approximation failure.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "stochastic representation Kraus decomposition",
        "non-Markovian quantum channels",
        "coherent error structured noise",
        "quantum channel approximation fidelity",
        "noise model adequacy quantum computing"
      ],
      "similarity": 0.5755578279495239,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "Additive Gaussian noise channel",
      "concept_b": "non-stochastic noise",
      "research_question": "How do non-stochastic (coherent and correlated) noise models affect the Shannon capacity and achievable rates of quantum channels, and can classical Additive Gaussian Noise (AWGN) capacity formulas be extended or corrected to account for coherence structure in realistic quantum error channels?",
      "why_unexplored": "Classical information theory has deeply characterized AWGN channels (1948–present), while quantum error correction and quantum channel capacity research separately developed models of non-stochastic noise (coherent errors, unitary perturbations, correlated dephasing). The literatures remain siloed: classical IT assumes stochasticity; quantum IT acknowledges coherence but rarely quantifies how much capacity is lost when classical AWGN assumptions fail in quantum substrates. No bridging framework systematically compares performance of AWGN-derived bounds against coherent-error regimes.",
      "intersection_opportunity": "Developing a unified capacity analysis that treats AWGN as a special (fully-decohered) case of a broader non-stochastic noise algebra could yield: (1) tighter, coherence-aware bounds on quantum communication rates; (2) design principles for quantum codes that exploit coherence structure rather than merely averaging over it; (3) provable gaps between AWGN-derived and coherent-error capacities, quantifying the cost of ignoring phase correlations in quantum channel design.",
      "methodology": "1. Formalize non-stochastic noise as a coherent noise model (e.g., Kraus operators with non-commuting, time-correlated terms) and derive its HSW (Holevo–Schumacher–Westmoreland) capacity. 2. Compare against AWGN-derived upper bounds by computing the coherent information and private capacity for canonical families (phase-flip noise, amplitude-phase correlated errors, systematic errors). 3. Construct a spectral decomposition showing how AWGN capacity emerges as a limit of averaging over coherent error ensembles. 4. Numerically simulate both models on small quantum systems (2–4 qubits) to validate analytic predictions. 5. Propose a coherence-aware modification to standard capacity formulas and test on simulated quantum networks.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "quantum channel capacity coherent errors",
        "Gaussian noise non-stochastic quantum noise",
        "Kraus operator coherence structure",
        "HSW capacity correlated errors",
        "quantum error correction AWGN approximation"
      ],
      "similarity": 0.5754579305648804,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "Colored Noise",
      "concept_b": "non-stochastic noise",
      "research_question": "To what extent do colored noise characteristics in quantum channels induce non-stochastic (coherent and correlated) error structures, and can we predict the emergence of non-stochastic errors from first-principles models of colored noise in quantum systems?",
      "why_unexplored": "Colored noise in quantum systems has been studied primarily through spectral and correlation-time lenses in decoherence theory, while non-stochastic errors are treated as separate phenomena arising from gate implementation imperfections and environmental coupling asymmetries. The community has not systematically investigated whether the temporal and spectral structure of colored noise *mechanistically generates* coherent error components, likely because quantum error correction has traditionally assumed Markovian or weakly non-Markovian noise, and non-stochastic errors are often viewed as design flaws rather than natural consequences of realistic noise spectra.",
      "intersection_opportunity": "Characterizing the colored-noise-to-non-stochastic-error mapping would enable: (1) predictive models for realistic quantum channel capacities that account for coherent error leakage from colored noise environments; (2) tailored quantum error correction codes that explicitly exploit the structure of colored noise to suppress emergent non-stochastic errors; (3) hardware design principles that actively shape environmental noise spectra to minimize coherent error components. This intersection bridges quantum information theory and experimental quantum control, potentially improving the efficiency frontier of near-term quantum devices.",
      "methodology": "First, systematically parameterize colored noise models (1/f, Ornstein-Uhlenbeck, etc.) acting on qubit ensembles and simulate open-system dynamics using Lindbladian formalism with memory kernels. Second, extract effective error channels from long-timescale simulations and decompose them into stochastic vs. coherent components using quantum channel distillation and process tomography analysis. Third, derive analytical conditions linking colored noise spectral moments to coherent error amplitude thresholds. Fourth, validate predictions experimentally using superconducting qubits or trapped ions with tunable environmental noise spectra (e.g., via magnetic field noise engineering). Fifth, benchmark whether error-correction codes informed by colored-noise structure outperform standard codes on simulated and real hardware.",
      "computational": true,
      "novelty": 5,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "colored noise quantum decoherence",
        "non-stochastic errors quantum channels",
        "non-Markovian noise coherent error leakage",
        "quantum error correction correlated noise",
        "1/f noise quantum gates",
        "memory effects quantum noise channels"
      ],
      "similarity": 0.5743305683135986,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.85
    },
    {
      "concept_a": "Partially Coherent Channels",
      "concept_b": "coherent states",
      "research_question": "How does the degree and structure of partial coherence in quantum communication channels affect the capacity to encode and transmit classical information using coherent states, and can we design channel-adaptive coherent state alphabets that exploit partial coherence to exceed standard quantum limits?",
      "why_unexplored": "Partially coherent channels and coherent states are studied in largely orthogonal literatures: coherent states dominate quantum optics and continuous-variable quantum information theory (treating channels as idealized), while partially coherent channels appear primarily in classical optics and decoherence theory without explicit connection to quantum communication alphabets. The mismatch arises because coherent state theory assumes or requires high coherence regimes, whereas partial coherence is typically treated as a degradation problem rather than a communication resource to be exploited.",
      "intersection_opportunity": "Characterizing how partial coherence affects coherent-state channel capacity could unlock new coding strategies that use the structure of partial coherence as a feature rather than fighting it as noise. This bridges decoherence theory (physics of partial coherence) with classical-information-over-quantum-channels (information theory), enabling hybrid protocols that trade coherence properties for improved noise robustness or scalability in near-term quantum networks.",
      "methodology": "First, parametrize partially coherent channels using density-matrix tools (Stokes parameters, coherency matrices) and map how coherence loss affects the distinguishability of coherent-state ensembles via quantum Fisher information and Helstrom bounds. Second, compute classical capacity numerically for toy channels (e.g., amplitude damping, dephasing) with varying coherence profiles using semidefinite programming. Third, design and test adaptive coherent-state constellations (e.g., reduced alphabet, rotated phases) optimized for specific partial-coherence signatures. Finally, compare against worst-case (incoherent) baselines and ideal (fully coherent) limits to identify the regime where partial coherence matters.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "partially coherent channels",
        "coherent states quantum capacity",
        "continuous-variable quantum communication",
        "coherence-assisted communication",
        "quantum channel discrimination",
        "decoherence and phase space"
      ],
      "similarity": 0.5713846683502197,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "White Noise Model",
      "concept_b": "stochastic noise",
      "research_question": "How do white noise models from classical information theory relate to stochastic noise characterization in quantum error correction, and can classical AWGN channel capacity bounds be adapted to predict quantum channel thresholds under realistic stochastic error distributions?",
      "why_unexplored": "White noise models (flat spectrum, Gaussian) are foundational in classical information theory but treated as oversimplifications in quantum computing, where noise is typically characterized operationally via quantum channels and error rates. The literature has siloed these: classical information theorists study AWGN capacity under idealized assumptions, while quantum error correction focuses on empirical stochastic error distributions (depolarizing, amplitude damping) that violate white noise assumptions. The conceptual bridge—whether and how classical white noise theory constrains or informs quantum noise models—remains largely absent.",
      "intersection_opportunity": "Formalizing the relationship could yield: (1) closed-form predictions for quantum error thresholds by mapping realistic stochastic noise to equivalent white noise characterizations, enabling faster threshold estimation; (2) new rate-distortion bounds for quantum-classical hybrid systems that inherit guarantees from AWGN theory; (3) a unified noise taxonomy that clarifies when quantum noise is *effectively* white (flat spectrum in appropriate Fourier basis) and when it fundamentally deviates, improving experimental noise characterization protocols.",
      "methodology": "Step 1: Parametrize stochastic quantum noise models (depolarizing, amplitude damping, dephasing) as quantum channels and compute their power spectral densities in the Kraus operator basis. Step 2: Derive effective white noise equivalents by minimizing KL-divergence or worst-case fidelity loss between the true stochastic channel and a white noise model. Step 3: Compare quantum error thresholds (e.g., surface code) computed under fitted white noise vs. exact stochastic models via Monte Carlo simulation. Step 4: Test whether classical AWGN capacity bounds (e.g., Shannon limit, turbo code performance) yield testable predictions for quantum codes under stochastic noise. Step 5: Validate on real quantum processor noise profiles (e.g., IBMQ, Quantinuum data) to assess when white noise approximation remains valid.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "methodological",
      "keywords": [
        "white noise model quantum channels",
        "stochastic noise characterization quantum error correction",
        "AWGN approximation quantum noise",
        "quantum channel capacity threshold",
        "spectral properties quantum error models"
      ],
      "similarity": 0.5615134239196777,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.0
    },
    {
      "concept_a": "Partially Coherent Channels",
      "concept_b": "non-stochastic noise",
      "research_question": "How do partially coherent channels degrade information capacity under non-stochastic (coherent and correlated) noise models, and can channel coherence properties be exploited to either mitigate or detect such structured errors in quantum communication systems?",
      "why_unexplored": "Partially coherent channels have been studied primarily in classical optics and limited quantum-optical contexts, while non-stochastic noise (especially coherent errors and correlations) has been analyzed mainly in quantum error correction and fault tolerance literature with Pauli/unitary noise assumptions. The two communities use different mathematical formalisms (density matrix coherence measures vs. Kraus operators and error models) and have not systematically characterized how partial coherence interacts with non-stochastic noise structure.",
      "intersection_opportunity": "Characterizing this intersection could reveal whether partial coherence in quantum channels can serve as both a vulnerability vector (amplifying structured error effects) and a resource (enabling coherence-assisted error detection or adaptive noise-resilient encoding). This opens new design principles for quantum repeaters and distributed quantum computing where coherence preservation and structured error resilience are jointly optimized.",
      "methodology": "1. Formally extend the partially coherent channel model (coherence quantified via off-diagonal density matrix structure) to include non-stochastic noise (modeled as fixed unitary/correlated perturbations rather than random Pauli channels). 2. Compute information-theoretic capacity (classical and quantum) for this hybrid model analytically and numerically for canonical examples (phase damping with superimposed dephasing, amplitude damping with coherent drive errors). 3. Develop a detector that distinguishes partially coherent signals corrupted by non-stochastic vs. stochastic noise using channel tomography and coherence witnesses. 4. Benchmark against existing quantum error correction codes to identify regimes where coherence-aware codes outperform standard approaches. 5. Validate predictions experimentally using trapped-ion or superconducting qubit platforms where coherence and error structure are both accessible.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "partially coherent quantum channels",
        "non-stochastic noise coherent errors",
        "quantum channel capacity structured noise",
        "coherence-aware error correction",
        "correlated Markovian errors quantum",
        "coherent error mitigation"
      ],
      "similarity": 0.553778886795044,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "Spectral Loss",
      "concept_b": "Sender-receiver channel",
      "research_question": "Does spectral loss in partially coherent quantum channels exhibit a quantifiable causal relationship with sender-receiver fidelity degradation, and can this relationship be characterized through a unified information-theoretic framework that predicts error thresholds for quantum communication protocols?",
      "why_unexplored": "Spectral loss has been studied primarily in classical coherence theory and optics contexts, while quantum sender-receiver channels are analyzed through decoherence and noise models that rarely decompose environmental effects by frequency-dependent mechanisms. The two communities operate with different mathematical formalisms (coherence-preserving measures vs. Kraus operators), creating a semantic boundary that obscures the mechanistic link between spectral degradation and quantum information leakage. Additionally, most quantum channel models treat noise as frequency-agnostic, missing the structured spectral information that could enable better error-correction strategies.",
      "intersection_opportunity": "A unified theory connecting spectral loss to quantum channel capacity would enable design of frequency-selective quantum error correction codes and noise-resilient pulse shaping for quantum communication. This intersection could reveal whether certain frequency bands are preferentially degraded during transmission, allowing protocol designers to concentrate quantum information encoding in robust spectral regions. Such insights would directly improve practical quantum repeaters and long-distance quantum networks by predicting which frequency multiplexing strategies preserve coherence longest.",
      "methodology": "1) Reformulate the spectral loss framework from 1003.6091v3 in the language of quantum operations: represent partially coherent channels as convex mixtures of coherent and incoherent components parameterized by frequency-dependent loss functions. 2) Develop an experimentally testable model linking spectral loss profiles to the Choi matrix representation of sender-receiver channels, deriving closed-form expressions for how spectral degradation reduces channel capacity. 3) Conduct numerical simulations on canonical quantum channels (amplitude damping, dephasing, depolarizing) modified with frequency-dependent loss envelopes, measuring fidelity degradation as a function of spectral bandwidth and loss profile. 4) Validate predictions against existing experimental data from quantum repeater testbeds (e.g., trapped-ion or photonic systems) where frequency characterization is available, extracting empirical spectral loss coefficients. 5) Propose a Bayesian inference method to recover spectral loss parameters from channel tomography data, enabling in-situ diagnosis of which frequency regions are most vulnerable in deployed quantum networks.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "spectral loss quantum channels",
        "frequency-dependent decoherence",
        "quantum channel capacity spectral characterization",
        "sender-receiver fidelity degradation mechanisms",
        "spectral quantum error correction",
        "partially coherent quantum communication"
      ],
      "similarity": 0.5500103235244751,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.5
    },
    {
      "concept_a": "Colored Noise",
      "concept_b": "stochastic noise",
      "research_question": "How do colored noise correlations in quantum systems affect the error correction capacity and fault-tolerance thresholds of quantum codes, and can this be exploited to design noise-resilient quantum architectures?",
      "why_unexplored": "The quantum computing literature treats stochastic noise as typically uncorrelated (white), while colored noise theory remains largely confined to classical signal processing and condensed matter physics. The field has not systematically investigated how temporal and spectral correlations in quantum noise sources—ubiquitous in superconducting qubits, trapped ions, and photonic systems—fundamentally alter the assumptions underlying quantum error correction and fault tolerance. This gap persists because colored noise modeling requires joint expertise in stochastic processes, quantum information, and experimental hardware characterization, disciplines rarely combined.",
      "intersection_opportunity": "A rigorous theory connecting colored noise profiles to quantum error correction thresholds could enable: (1) predictive design of quantum hardware tolerant to realistic correlated noise, (2) development of noise-adaptive error correction codes that exploit spectral structure rather than fighting it, and (3) better calibration and validation protocols that distinguish colored from white noise in real devices. This could shift quantum computing from worst-case white-noise assumptions to hardware-matched noise models, substantially improving practical error rates.",
      "methodology": "First, characterize the noise power spectrum of leading quantum platforms (superconducting qubits, trapped ions) via spectral density tomography or Wiener–Khinchin analysis of gate fidelity data from published papers (2111.00496v4, 2512.02760v1) and device reports. Second, model colored noise using parametric families (1/f, Ornstein–Uhlenbeck, multi-pole) and inject these into quantum circuit simulations with established error correction codes (surface codes, stabilizer codes). Third, compute fault-tolerance thresholds as functions of noise spectral parameters and compare against white-noise predictions. Fourth, design noise-adaptive codes by exploiting correlation structure (e.g., detuned syndrome extraction to filter specific frequencies). Finally, validate predictions on hardware by engineering filtered noise injection or selecting natural noise regimes that approximate target colored profiles.",
      "computational": true,
      "novelty": 4,
      "tractability": 4,
      "impact": 5,
      "bridge_type": "causal",
      "keywords": [
        "colored noise quantum error correction",
        "1/f noise fault tolerance thresholds",
        "correlated quantum noise characterization",
        "noise-adaptive quantum codes",
        "spectral noise tomography superconducting qubits",
        "temporal correlations quantum fault tolerance"
      ],
      "similarity": 0.549004316329956,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.9
    },
    {
      "concept_a": "Kolmogorov Complexity",
      "concept_b": "sample complexity",
      "research_question": "Does the Kolmogorov complexity of a quantum algorithm's description fundamentally constrain the sample complexity required to learn or verify its output distribution, and can this constraint be made quantitative and exploitable for quantum algorithm design?",
      "why_unexplored": "Kolmogorov complexity operates in the classical uncomputable domain (undecidability), while sample complexity is grounded in statistical learning theory and quantum measurement. The two communities rarely intersect: quantum computing researchers focus on gate counts and measurement repetitions (empirical sample complexity), while algorithmic information theorists study asymptotic descriptional bounds that appear disconnected from practical sampling regimes. The bridge requires formalizing how classical program length relates to quantum measurement statistics—a distinctly interdisciplinary question.",
      "intersection_opportunity": "Establishing a formal relationship could yield lower bounds on quantum sample complexity from the Kolmogorov complexity of the target state or algorithm, enabling principled design of quantum learners. Conversely, empirical sample complexity measurements on quantum processors could provide evidence for or against conjectures about the compressibility of quantum-generated data. This intersection could spawn a new field of 'quantum algorithmic information theory' combining descriptional complexity with measurement efficiency.",
      "methodology": "1. Formalize a mapping from Kolmogorov complexity K(x) of a binary description of a quantum circuit to a lower bound on samples needed to distinguish its output distribution from noise (via quantum information-theoretic tools: fidelity, relative entropy, trace distance). 2. Prove or disprove whether K(circuit) ≥ Ω(sample_complexity) under reasonable encoding schemes, using existing toolkit from communication complexity and quantum state tomography. 3. Empirically test the prediction on NISQ devices: design parameterized quantum circuits of varying descriptional length, measure required sample counts for state certification, and correlate against K-complexity proxies (compression ratios of circuit descriptions). 4. Explore whether this relationship enables a new quantum circuit synthesis method: optimize both circuit depth and description length jointly to minimize inferred sample complexity.",
      "computational": true,
      "novelty": 5,
      "tractability": 3,
      "impact": 4,
      "bridge_type": "causal",
      "keywords": [
        "Kolmogorov complexity quantum circuits",
        "sample complexity quantum learning",
        "quantum circuit synthesis compression",
        "algorithmic information theory quantum",
        "quantum state tomography sample bounds",
        "quantum circuit description length"
      ],
      "similarity": 0.5488006472587585,
      "graph_distance": 999,
      "structural_hole_score": 0.5,
      "approved": null,
      "composite_score": 4.6
    }
  ]
}